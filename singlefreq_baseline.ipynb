{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'sinusoid_dataset.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "features = df['Feature'].apply(lambda x: np.array([float(val.strip(\"[]\")) for val in x.split()])).values\n",
    "labels = df['Label'].apply(lambda x: np.array([float(val.strip(\"[]\")) for val in x.split(',')])).values\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1)\n"
     ]
    }
   ],
   "source": [
    "padded_array = pad_sequences(labels, padding='post', maxlen=1)\n",
    "print(padded_array.shape)\n",
    "labels = np.vstack(padded_array)\n",
    "features = np.vstack(features)\n",
    "#scaler = MinMaxScaler()\n",
    "#features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 11:25:19.466303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.643065: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.643133: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.649100: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.649173: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.649214: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.990778: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.990876: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.990888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-10 11:25:19.990942: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 11:25:19.990965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6087 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80000, 299)\n",
      "X_test shape: (20000, 299)\n",
      "y_train_categorical shape: (80000, 1)\n",
      "y_test_categorical shape: (20000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train_categorical shape:\", y_train.shape)\n",
    "print(\"y_test_categorical shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 299, 299)          359996    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 299, 299)          1196      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 299, 128)          219136    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 299, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632617 (2.41 MB)\n",
      "Trainable params: 631635 (2.41 MB)\n",
      "Non-trainable params: 982 (3.84 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(299, input_shape=(299, 1), return_sequences=True))\n",
    "model.add(layers.BatchNormalization())  # Batch normalization can be helpful\n",
    "model.add(layers.LSTM(128, return_sequences=True))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LSTM(64, return_sequences=False))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='tanh'))\n",
    "model.add(layers.Dense(1))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 43s 157ms/step - loss: 41.3292 - mae: 41.3292 - mse: 2456.4709 - mape: 75.6508 - val_loss: 35.3539 - val_mae: 35.3539 - val_mse: 1910.1240 - val_mape: 61.8682\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 38s 152ms/step - loss: 31.1475 - mae: 31.1475 - mse: 1611.6089 - mape: 50.8509 - val_loss: 28.5057 - val_mae: 28.5057 - val_mse: 1365.5098 - val_mape: 47.6703\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 25.2104 - mae: 25.2104 - mse: 1155.6050 - mape: 40.8702 - val_loss: 22.5856 - val_mae: 22.5856 - val_mse: 979.1346 - val_mape: 35.0796\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 39s 158ms/step - loss: 20.2251 - mae: 20.2251 - mse: 826.9146 - mape: 30.5223 - val_loss: 19.0963 - val_mae: 19.0963 - val_mse: 702.6180 - val_mape: 30.0776\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 16.2255 - mae: 16.2255 - mse: 585.2357 - mape: 23.9884 - val_loss: 14.3978 - val_mae: 14.3978 - val_mse: 489.7323 - val_mape: 21.2914\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 12.9615 - mae: 12.9615 - mse: 408.4164 - mape: 19.8851 - val_loss: 12.2949 - val_mae: 12.2949 - val_mse: 345.3664 - val_mape: 18.6400\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 38s 151ms/step - loss: 10.2210 - mae: 10.2210 - mse: 280.1400 - mape: 15.8056 - val_loss: 9.0669 - val_mae: 9.0669 - val_mse: 230.0642 - val_mape: 14.0409\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 8.0119 - mae: 8.0119 - mse: 188.9952 - mape: 12.6177 - val_loss: 6.9689 - val_mae: 6.9689 - val_mse: 154.3066 - val_mape: 11.3043\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 38s 154ms/step - loss: 6.2837 - mae: 6.2837 - mse: 125.6036 - mape: 11.4761 - val_loss: 5.4246 - val_mae: 5.4246 - val_mse: 101.2575 - val_mape: 9.8460\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 4.9447 - mae: 4.9447 - mse: 81.8741 - mape: 10.1419 - val_loss: 4.5545 - val_mae: 4.5545 - val_mse: 66.4059 - val_mape: 9.0679\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 3.7684 - mae: 3.7684 - mse: 52.0672 - mape: 7.8156 - val_loss: 3.2708 - val_mae: 3.2708 - val_mse: 41.5193 - val_mape: 7.2992\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 56s 224ms/step - loss: 3.1333 - mae: 3.1333 - mse: 33.7490 - mape: 8.1233 - val_loss: 2.7952 - val_mae: 2.7952 - val_mse: 27.0054 - val_mape: 7.2336\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 2.4829 - mae: 2.4829 - mse: 21.3410 - mape: 7.2643 - val_loss: 2.1508 - val_mae: 2.1508 - val_mse: 16.8476 - val_mape: 6.8260\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 63s 250ms/step - loss: 2.0613 - mae: 2.0613 - mse: 14.1833 - mape: 7.0998 - val_loss: 2.0525 - val_mae: 2.0525 - val_mse: 13.4759 - val_mape: 9.8822\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 55s 222ms/step - loss: 1.6701 - mae: 1.6701 - mse: 9.0949 - mape: 5.8105 - val_loss: 1.2197 - val_mae: 1.2197 - val_mse: 6.4975 - val_mape: 3.3030\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 1.2851 - mae: 1.2851 - mse: 5.4282 - mape: 3.7468 - val_loss: 1.2455 - val_mae: 1.2455 - val_mse: 4.7915 - val_mape: 2.8398\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 97s 389ms/step - loss: 1.0485 - mae: 1.0485 - mse: 3.4330 - mape: 3.1921 - val_loss: 0.8074 - val_mae: 0.8074 - val_mse: 2.5274 - val_mape: 2.4955\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 74s 297ms/step - loss: 0.9732 - mae: 0.9732 - mse: 2.4941 - mape: 3.3655 - val_loss: 0.8900 - val_mae: 0.8900 - val_mse: 1.9474 - val_mape: 3.8568\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 71s 284ms/step - loss: 0.7597 - mae: 0.7597 - mse: 1.5003 - mape: 2.7044 - val_loss: 0.6469 - val_mae: 0.6469 - val_mse: 1.1144 - val_mape: 2.1258\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.7120 - mae: 0.7120 - mse: 1.1775 - mape: 2.8538 - val_loss: 0.7349 - val_mae: 0.7349 - val_mse: 1.0207 - val_mape: 2.6941\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.7364 - mae: 0.7364 - mse: 1.0260 - mape: 2.7091\n",
      "Test Loss: 0.7364\n",
      "Test MAE: 0.7364\n",
      "Test MSE: 1.0260\n",
      "Test MAPE: 2.7091\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['mae', 'mse', 'mape'])\n",
    "#overfitCallback = EarlyStopping(monitor='loss', min_delta=0, patience = 4)\n",
    "#lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-7)\n",
    "model.fit(X_train_tensor, y_train_tensor, epochs=20, batch_size=256, validation_split=0.2)\n",
    "test_loss, test_mae, test_mse, test_mape = model.evaluate(X_test_tensor, y_test_tensor)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test MAE: {test_mae:.4f}')\n",
    "print(f'Test MSE: {test_mse:.4f}')\n",
    "print(f'Test MAPE: {test_mape:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1)\n",
      "(8, 299)\n",
      "[[2.39770275]\n",
      " [2.37782306]\n",
      " [2.37742957]\n",
      " [2.37666683]\n",
      " [2.37638921]\n",
      " [2.37874752]\n",
      " [2.37809528]\n",
      " [2.37756972]]\n",
      "Real Sinusoid Tests:\n",
      "\n",
      "[[1]]\n",
      "1/1 [==============================] - 1s 725ms/step\n",
      "[[1.594873]]\n",
      "[[10]]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "[[9.389566]]\n",
      "[[19]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[18.276806]]\n",
      "[[27]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[26.469257]]\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "[[35.501297]]\n",
      "[[45]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[45.40043]]\n",
      "[[54]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[53.19606]]\n",
      "[[90]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[91.0962]]\n",
      "Synthetic Sinusoid Tests:\n",
      "\n",
      "[[51]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[50.510677]]\n",
      "[[54]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[[53.655098]]\n",
      "[[7]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[[7.565708]]\n",
      "[[16]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[17.121113]]\n",
      "[[43]]\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "[[42.54716]]\n",
      "[[12]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[12.465622]]\n",
      "[[23]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "[[23.592072]]\n",
      "[[52]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "[[51.74625]]\n",
      "[[43]]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[42.174526]]\n",
      "[[2]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "[[2.3628497]]\n",
      "[[75]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[76.47786]]\n",
      "[[27]]\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "[[27.75121]]\n",
      "[[37]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[36.70086]]\n",
      "[[80]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[81.24249]]\n",
      "[[84]]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "[[83.85005]]\n",
      "[[91]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[90.59996]]\n",
      "[[7]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[7.1894994]]\n",
      "[[34]]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "[[34.508434]]\n",
      "[[79]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[80.5811]]\n",
      "[[55]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "[[54.419777]]\n",
      "[[75]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[76.19025]]\n",
      "[[11]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "[[11.278544]]\n",
      "[[50]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "[[49.046898]]\n",
      "[[7]]\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "[[7.7537384]]\n",
      "[[42]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[41.892525]]\n",
      "[[30]]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[30.087727]]\n",
      "[[65]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[64.93344]]\n",
      "[[23]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[[23.651783]]\n",
      "[[46]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "[[46.039272]]\n",
      "[[9]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[10.298376]]\n",
      "[[7]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[8.076233]]\n",
      "[[32]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "[[32.39657]]\n",
      "[[82]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "[[82.62657]]\n",
      "[[38]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[37.82994]]\n",
      "[[10]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[10.772354]]\n",
      "[[23]]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "[[24.342857]]\n",
      "[[80]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "[[81.219376]]\n",
      "[[6]]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[6.3761563]]\n",
      "[[49]]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[[48.298676]]\n",
      "[[75]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[75.344284]]\n",
      "[[73]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "[[73.45973]]\n",
      "[[18]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[19.773685]]\n",
      "[[85]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[84.74597]]\n",
      "[[79]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[79.90609]]\n",
      "[[72]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[73.49983]]\n",
      "[[79]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[79.875916]]\n",
      "[[41]]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[[40.854965]]\n",
      "[[54]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "[[53.62216]]\n",
      "[[96]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "[[94.95468]]\n",
      "[[32]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[32.465706]]\n",
      "[[54]]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[53.567467]]\n",
      "[[15]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[16.048077]]\n",
      "[[48]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[47.262196]]\n",
      "[[17]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[17.948275]]\n",
      "[[59]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[58.416]]\n",
      "[[41]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[[40.78667]]\n",
      "[[18]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[18.643139]]\n",
      "[[76]]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[77.29902]]\n",
      "[[47]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[46.805]]\n",
      "[[4]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "[[4.378252]]\n",
      "[[17]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[17.993855]]\n",
      "[[97]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[94.965775]]\n",
      "[[92]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "[[92.85574]]\n",
      "[[95]]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[[94.70557]]\n",
      "[[17]]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "[[17.32903]]\n",
      "[[28]]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[28.851295]]\n",
      "[[63]]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[62.00244]]\n",
      "[[20]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[21.234447]]\n",
      "[[90]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[90.53046]]\n",
      "[[5]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[4.0601015]]\n",
      "[[58]]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[57.121227]]\n",
      "[[20]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "[[21.319141]]\n",
      "[[82]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "[[82.22415]]\n",
      "[[27]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[27.436844]]\n",
      "[[52]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "[[51.55495]]\n",
      "[[6]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[[7.0203133]]\n",
      "[[56]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "[[55.578888]]\n",
      "[[36]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[35.993305]]\n",
      "[[94]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[93.86925]]\n",
      "[[88]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[[88.21832]]\n",
      "[[74]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "[[74.7549]]\n",
      "[[73]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[[74.03766]]\n",
      "[[33]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[33.091972]]\n",
      "[[19]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "[[19.796036]]\n",
      "[[30]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "[[29.86987]]\n",
      "[[97]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[94.897125]]\n",
      "[[84]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[83.62515]]\n",
      "[[46]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "[[45.787895]]\n",
      "[[15]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[[15.886161]]\n",
      "[[32]]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "[[32.2508]]\n",
      "[[57]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[56.19059]]\n",
      "[[94]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[94.450455]]\n",
      "[[33]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "[[32.904034]]\n",
      "[[38]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "[[37.414883]]\n",
      "[[9]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[9.707975]]\n",
      "[[72]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[72.648026]]\n",
      "[[48]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "[[47.49414]]\n",
      "[[1]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[0.85900545]]\n",
      "[[91]]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "[[90.94892]]\n",
      "[[75]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[[76.48999]]\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'samplesreal.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Extract features and labels\n",
    "features = df['Feature'].apply(lambda x: np.array([float(val.strip(\"[]\")) for val in x.split(',')])).values\n",
    "\n",
    "# Convert the string of up to 5 numbers to a NumPy array of floats\n",
    "labels = df['Label'].values\n",
    "labels = np.vstack(labels)\n",
    "features = np.vstack(features)\n",
    "\n",
    "print(labels.shape)\n",
    "print(features.shape)\n",
    "\n",
    "means = np.mean(features, axis=1, keepdims=True)\n",
    "print(means)\n",
    "features = features - means\n",
    "#change to 50\n",
    "features = features * 50\n",
    "print(\"Real Sinusoid Tests:\\n\")\n",
    "for i in range(8):\n",
    "  print(labels[i:i+1])\n",
    "  print(model.predict(features[i:i+1]))\n",
    "print(\"Synthetic Sinusoid Tests:\\n\")\n",
    "for i in range(100):\n",
    "  print(y_test[i:i+1])\n",
    "  print(model.predict(X_test[i:i+1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
